{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fmore\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "import sqlvalidator\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sqlparse.sql import Identifier, IdentifierList\n",
    "from sqlparse.tokens import Keyword, DML, Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"xlangai/spider\")\n",
    "\n",
    "train_dataset = dataset[\"train\"].to_pandas()\n",
    "test_dataset = dataset[\"validation\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT T2.student_details FROM student_course_registrations AS T1 JOIN students AS T2 ON T1.student_id = T2.student_id ORDER BY T1.registration_date DESC LIMIT 1\n"
     ]
    }
   ],
   "source": [
    "query = train_dataset.iloc[67][\"query\"]\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_between_keywords(sql):\n",
    "    parsed = sqlparse.parse(sql)[0]  # Parse the SQL statement\n",
    "    tokens = parsed.tokens\n",
    "    \n",
    "    words_between = []  # To store words between keywords\n",
    "    current_keywords = []\n",
    "    buffer = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.ttype in (Keyword, DML):  # Check if the token is a keyword\n",
    "            if buffer:  # If there are words in the buffer, add them\n",
    "                words_between.append((current_keywords[-1] if current_keywords else None, buffer))\n",
    "                buffer = []\n",
    "            current_keywords.append(token.value.upper())\n",
    "        elif token.ttype is Whitespace:  # Ignore whitespace\n",
    "            continue\n",
    "        else:\n",
    "            if isinstance(token, (Identifier, IdentifierList)):\n",
    "                buffer.append(token.get_real_name() or token.value)\n",
    "            else:\n",
    "                buffer.append(token.value)\n",
    "    \n",
    "    if buffer:  # Add remaining buffer\n",
    "        words_between.append((current_keywords[-1] if current_keywords else None, buffer))\n",
    "    \n",
    "    return words_between\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred: str, ground_truth: str):\n",
    "\n",
    "    \"\"\"Compare 2 queries on their semantic\n",
    "    \n",
    "    Return :\n",
    "    \n",
    "    - valid_pred : True if te pred query is semanticaly correct, False otherwise. It is not really reliable.\n",
    "    - keyword_score [0, 1]: Equivalent of F1 score for SQL keywords presence. The pred query must contains the keywords of the ground truth without adding new keywords.\n",
    "    - identifier_score [0, 1]: For each keywords, f1 score is computed for identifiers words (table name, attributes...). The average gives the identifier_score.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Check if the predicted query is semanticaly correct\n",
    "    parsed_pred = sqlvalidator.parse(pred)\n",
    "    valid_pred = False\n",
    "    try:\n",
    "        if parsed_pred.is_valid():\n",
    "            valid_pred = True\n",
    "    except:\n",
    "        valid_pred = False\n",
    "\n",
    "    # Normalize queries\n",
    "    normalized_pred = sqlparse.format(pred, reindent=False, keyword_case='upper')\n",
    "    normalized_gt = sqlparse.format(ground_truth, reindent=False, keyword_case='upper')\n",
    "\n",
    "    # Compare Semantic of queries\n",
    "    tokens_pred = get_words_between_keywords(normalized_pred)\n",
    "    tokens_gt = get_words_between_keywords(normalized_gt)\n",
    "\n",
    "    \"\"\"example of tokens_pred or tokens_gt : \n",
    "    \n",
    "    [('SELECT', ['Status']),\n",
    "    ('FROM', ['city']),\n",
    "    ('GROUP BY', ['Status']),\n",
    "    ('ORDER BY', ['COUNT(*)', 'DESC']),\n",
    "    ('LIMIT', ['1'])]\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_f1score(a: set, b: set):\n",
    "        \"\"\"Equivalent of F1 score metric\"\"\"\n",
    "        TP = len(a & b)\n",
    "        FP = len(a - b)\n",
    "        FN = len(b - a)\n",
    "\n",
    "        return TP / (TP + 0.5*(FP + FN))\n",
    "\n",
    "    ## Keyword score\n",
    "\n",
    "    keywords_pred = set([elem[0] for elem in tokens_pred])\n",
    "    keywords_gt = set([elem[0] for elem in tokens_gt])\n",
    "\n",
    "    keyword_score = compute_f1score(keywords_pred, keywords_gt)\n",
    "    \n",
    "    ## Identifier score\n",
    "\n",
    "    identifier_score = 0\n",
    "    commun_keywords = keywords_pred & keywords_gt\n",
    "    for kw in list(commun_keywords):\n",
    "        identifiers_pred = next((item for item in tokens_pred if item[0] == kw), None)[1]\n",
    "        identifiers_gt = next((item for item in tokens_gt if item[0] == kw), None)[1]\n",
    "\n",
    "        identifier_score += compute_f1score(set(identifiers_pred), set(identifiers_gt))\n",
    "    \n",
    "    identifier_score = identifier_score / len(commun_keywords)\n",
    "\n",
    "    return valid_pred, keyword_score, identifier_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
